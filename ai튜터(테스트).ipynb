{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1QaCSoYhP2FfXGE_VkcImuQTyKFC1G-Hk",
      "authorship_tag": "ABX9TyPGD4u24IcWjSVlkt4iPlfh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kyungbok-ai-study/cyj/blob/main/ai%ED%8A%9C%ED%84%B0(%ED%85%8C%EC%8A%A4%ED%8A%B8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFpz_H5dEqQX",
        "outputId": "7664a56e-f947-4142-8e64-9da30fa7433f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ë²„ì „ ëª…ì‹œ)\n",
        "!pip install faiss-cpu langchain-text-splitters python-docx unstructured langchain_community llama-index gradio docx2txt -qqq\n",
        "!pip install --upgrade \"google-genai>=1.7.0\" \"langchain-google-genai>=2.1.3\" -qqq\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tDJ_m7Aq6XN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26cbdc00-a150-4269-d36f-36f902ea9f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m808.7/808.7 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.4/181.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.1/253.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m159.7/159.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1ë‹¨ê³„ : ë¬¸ì„œ ë¡œë“œ**"
      ],
      "metadata": {
        "id": "mc4Z5XeFj3rF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import Docx2txtLoader\n",
        "\n",
        "loader = Docx2txtLoader(\"/content/drive/MyDrive/(á„‚á…¡á†«á„‹á…µá„ƒá…©á„‘á…­á„‰á…µá„‡á…©á†«) á„‰á…¢á†·á„‘á…³á†¯á„†á…®á†«á„Œá…¦ á„‹á…¯á„ƒá…³á„…á…© á„ƒá…¡á„‰á…µ.docx\")  # ë¬¸ì„œ ë¡œë” ì´ˆê¸°í™”\n",
        "\n",
        "docs = loader.load()  # ë¬¸ì„œ ë¡œë”©\n",
        "\n",
        "print(len(docs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "demLNfoK4SEv",
        "outputId": "662a417e-c693-4500-e5c8-0e2004d1188f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### llmì´ ëª»ì•Œì•„ ë“¤ì„ ìˆ˜ ìˆìœ¼ë‹ˆ <br>**ì •ê·œ í‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ 'í•˜ N.', 'ì¤‘ N.', 'ìƒ N.'ì„ 'ë‚œì´ë„ í•˜ N.', 'ë‚œì´ë„ ì¤‘ N.', 'ë‚œì´ë„ ìƒ N.'ìœ¼ë¡œ ë³€í™˜**"
      ],
      "metadata": {
        "id": "EtcOc1UR0gI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def transform_difficulty_markers(docs):\n",
        "    for i, doc in enumerate(docs):\n",
        "        modified_content = re.sub(r'(í•˜|ì¤‘|ìƒ)( \\d+\\.)', r'ë‚œì´ë„ \\1\\2', doc.page_content)\n",
        "        docs[i].page_content = modified_content\n",
        "    return docs\n",
        "\n",
        "# ë³€í™˜ëœ ë¬¸ì„œ ì‚¬ìš©\n",
        "docs = transform_difficulty_markers(docs)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv2ry88STBCR",
        "outputId": "81a350f6-3bfa-47fe-c104-3e4c08f60f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ìƒ˜í”Œë¬¸ì œ (ì •ë‹µ ë° í•´ì„¤ í¬í•¨)\n",
            "\n",
            "ë‚œì´ë„ í•˜ 1. ë‹¤ìŒ ì¤‘ ê°„(liver)ì—ì„œ ìˆ˜í–‰í•˜ì§€ ì•ŠëŠ” ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€?\n",
            "\n",
            "A. ì•Œë¶€ë¯¼(albumin) í•©ì„±\n",
            "\n",
            "B. ë‹´ì¦™(bile) ìƒì„±\n",
            "\n",
            "C. í˜ˆë‹¹ ì¡°ì ˆ(glucose regulation)\n",
            "\n",
            "D. ì¸ìŠë¦°(insulin) ë¶„ë¹„\n",
            "\n",
            "ì •ë‹µ: D. ì¸ìŠë¦°(insulin) ë¶„ë¹„\n",
            " í•´ì„¤: ì¸ìŠë¦°ì€ ì·Œì¥(ì´ì)ì—ì„œ ë¶„ë¹„ë˜ë©°, ê°„ì€ ì•Œë¶€ë¯¼ í•©ì„±, ë‹´ì¦™ ìƒì„±, í˜ˆë‹¹ ì¡°ì ˆì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ ì¤‘ 2. ê·¼ìˆ˜ì¶•(muscle contraction)ì— ì§ì ‘ì ìœ¼ë¡œ ê´€ì—¬í•˜ëŠ” ë‹¨ë°±ì§ˆ ë³µí•©ì²´ë¡œ ì˜³ì€ ê²ƒì€?\n",
            "\n",
            "A. ë¯¸ì˜¤ì‹ (myosin)ê³¼ íŠ¸ë¡œí¬ë‹Œ(troponin)\n",
            "\n",
            "B. íŠ¸ë¡œí¬ë‹Œ(troponin)ê³¼ íŠ¸ë¡œí¬ë§ˆì´ì˜¤ì‹ (tropomyosin)\n",
            "\n",
            "C. ì•¡í‹´(actin)ê³¼ ì½œë¼ê²(collagen)\n",
            "\n",
            "D. ì—˜ë¼ìŠ¤í‹´(elastin)ê³¼ ë¯¸ì˜¤ì‹ (myosin)\n",
            "\n",
            "ì •ë‹µ: B. íŠ¸ë¡œí¬ë‹Œ(troponin)ê³¼ íŠ¸ë¡œí¬ë§ˆì´ì˜¤ì‹ (tropomyosin)\n",
            " í•´ì„¤: íŠ¸ë¡œí¬ë‹Œê³¼ íŠ¸ë¡œí¬ë§ˆì´ì˜¤ì‹ ì€ ê·¼ìˆ˜ì¶• ì‹œ ì¹¼ìŠ˜ê³¼ ê²°í•©í•˜ì—¬ ì•¡í‹´-ë¯¸ì˜¤ì‹  ìƒí˜¸ì‘ìš©ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ í•˜ 3. ë‹¤ìŒ ì¤‘ í˜ˆì•¡-ë‡Œ ì¥ë²½(blood-brain barrier)ì„ í†µê³¼í•˜ê¸° ê°€ì¥ ì‰¬ìš´ ë¬¼ì§ˆì€?\n",
            "\n",
            "A. í¬ë„ë‹¹(glucose)\n",
            "\n",
            "B. ì‚°ì†Œ(oxygen)\n",
            "\n",
            "C. ë‹¨ë°±ì§ˆ(protein)\n",
            "\n",
            "D. ë‚˜íŠ¸ë¥¨ ì´ì˜¨(sodium ion)\n",
            "\n",
            "ì •ë‹µ: B. ì‚°ì†Œ(oxygen)\n",
            " í•´ì„¤: ì‚°ì†ŒëŠ” ì§€ìš©ì„± ë¶„ìë¡œ, í˜ˆì•¡-ë‡Œ ì¥ë²½ì„ ê°€ì¥ ì‰½ê²Œ í†µê³¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ ì¤‘ 4. ì‹ ì¥ì—ì„œ ì—¬ê³¼(filtration)ê°€ ì¼ì–´ë‚˜ëŠ” ì£¼ìš” êµ¬ì¡°ë¬¼ì€?\n",
            "\n",
            "A. ë³´ìš°ë§Œì£¼ë¨¸ë‹ˆ(Bowman's capsule)\n",
            "\n",
            "B. ê·¼ìœ„ì„¸ë‡¨ê´€(proximal convoluted tubule)\n",
            "\n",
            "C. í—¨ë ˆê³ ë¦¬(loop of Henle)\n",
            "\n",
            "D. ì§‘í•©ê´€(collecting duct)\n",
            "\n",
            "ì •ë‹µ: A. ë³´ìš°ë§Œì£¼ë¨¸ë‹ˆ(Bowman's capsule)\n",
            " í•´ì„¤: ì‹ ì¥ì—ì„œ í˜ˆì•¡ì˜ ì—¬ê³¼ëŠ” ì‚¬êµ¬ì²´ì™€ ë³´ìš°ë§Œì£¼ë¨¸ë‹ˆì—ì„œ ì¼ì–´ë‚©ë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ ì¤‘ 5. ë‹¤ìŒ ì¤‘ ììœ¨ì‹ ê²½ê³„(autonomic nervous system)ì˜ êµê°ì‹ ê²½ê³„(sympathetic nervous system)ì˜ ë°˜ì‘ì´ ì•„ë‹Œ ê²ƒì€?\n",
            "\n",
            "A. ë™ê³µ í™•ëŒ€(pupil dilation)\n",
            "\n",
            "B. ì‹¬ë°•ìˆ˜ ì¦ê°€(increased heart rate)\n",
            "\n",
            "C. ì†Œí™”í™œë™ ì´‰ì§„(enhanced digestion)\n",
            "\n",
            "D. ê¸°ê´€ì§€ í™•ì¥(bronchodilation)\n",
            "\n",
            "ì •ë‹µ: C. ì†Œí™”í™œë™ ì´‰ì§„(enhanced digestion)\n",
            " í•´ì„¤: êµê°ì‹ ê²½ê³„ëŠ” ì†Œí™” í™œë™ì„ ì–µì œí•˜ê³ , ë¶€êµê°ì‹ ê²½ê³„ê°€ ì†Œí™”í™œë™ì„ ì´‰ì§„í•©ë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ ìƒ 6. í˜¸ë¥´ëª¬ ì¡°ì ˆ(hormonal regulation)ì— ìˆì–´ ìŒì„±ë˜ë¨¹ì„(negative feedback)ì˜ ì˜ˆë¡œ ì ì ˆí•œ ê²ƒì€?\n",
            "\n",
            "A. í˜ˆë‹¹ ì¦ê°€ ì‹œ ê¸€ë£¨ì¹´ê³¤(glucagon) ë¶„ë¹„ ì¦ê°€\n",
            "\n",
            "B. í˜ˆì¤‘ ì¹¼ìŠ˜ ë†ë„ ê°ì†Œ ì‹œ ì¹¼ì‹œí† ë‹Œ(calcitonin) ë¶„ë¹„ ì¦ê°€\n",
            "\n",
            "C. ê°‘ìƒì„  í˜¸ë¥´ëª¬(thyroid hormone) ì¦ê°€ ì‹œ TSH ê°ì†Œ\n",
            "\n",
            "D. ì²´ì˜¨ ì¦ê°€ ì‹œ ë•€ìƒ˜ ë¶„ë¹„ ê°ì†Œ\n",
            "\n",
            "ì •ë‹µ: C. ê°‘ìƒì„  í˜¸ë¥´ëª¬(thyroid hormone) ì¦ê°€ ì‹œ TSH ê°ì†Œ\n",
            " í•´ì„¤: ê°‘ìƒì„  í˜¸ë¥´ëª¬ì´ ì¦ê°€í•˜ë©´ ë‡Œí•˜ìˆ˜ì²´ì—ì„œ TSH ë¶„ë¹„ê°€ ì–µì œë˜ëŠ” ê²ƒì´ ëŒ€í‘œì ì¸ ìŒì„± í”¼ë“œë°±ì…ë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ ì¤‘ 7. ê·¼ìœ¡ì˜ ìœ í˜• ì¤‘ ì‹¬ì¥ê·¼(cardiac muscle)ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œ ì˜³ì§€ ì•Šì€ ê²ƒì€?\n",
            "\n",
            "A. ë¶ˆìˆ˜ì˜ê·¼(involuntary muscle)ì´ë‹¤.\n",
            "\n",
            "B. ê°„ê·¹ê²°í•©(gap junction)ì„ í¬í•¨í•œë‹¤.\n",
            "\n",
            "C. ìˆ˜ì¶•ì€ ììœ¨ì‹ ê²½ê³„ì— ì˜í•´ ì¡°ì ˆëœë‹¤.\n",
            "\n",
            "D. í•µì´ ë‹¤ìˆ˜ ì¡´ì¬í•œë‹¤.\n",
            "\n",
            "ì •ë‹µ: D. í•µì´ ë‹¤ìˆ˜ ì¡´ì¬í•œë‹¤.\n",
            " í•´ì„¤: ì‹¬ì¥ê·¼ì€ ëŒ€ë¶€ë¶„ ë‹¨ì¼ í•µì„ ê°€ì§€ë©° ë‹¤ìˆ˜ì˜ í•µì€ ê³¨ê²©ê·¼ì˜ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ í•˜ 8. í˜ˆì•¡ì˜ í•­ìƒì„±(homeostasis)ì„ ìœ ì§€í•˜ëŠ” ê³¼ì •ì—ì„œ í˜ˆì†ŒíŒ(platelets)ì˜ ì£¼ìš” ì—­í• ì€?\n",
            "\n",
            "A. ì‚°ì†Œ ìš´ë°˜\n",
            "\n",
            "B. ë©´ì—­ ë°˜ì‘ ì´‰ì§„\n",
            "\n",
            "C. í˜ˆì•¡ ì‘ê³  ì‹œì‘\n",
            "\n",
            "D. ì‚¼íˆ¬ì•• ìœ ì§€\n",
            "\n",
            "ì •ë‹µ: C. í˜ˆì•¡ ì‘ê³  ì‹œì‘\n",
            " í•´ì„¤: í˜ˆì†ŒíŒì€ í˜ˆê´€ì´ ì†ìƒë˜ì—ˆì„ ë•Œ í˜ˆì•¡ì‘ê³ ë¥¼ ì‹œì‘í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ ì¤‘ 9. ì‹ ê²½ì„¸í¬(neuron)ì˜ í™œë™ì „ìœ„(action potential)ì—ì„œ íƒˆë¶„ê·¹(depolarization)ì´ ì¼ì–´ë‚˜ëŠ” ì›ì¸ì€?\n",
            "\n",
            "A. ì¹¼ìŠ˜ ì´ì˜¨ì˜ ìœ ì…\n",
            "\n",
            "B. ì¹¼ë¥¨ ì´ì˜¨ì˜ ìœ ì¶œ\n",
            "\n",
            "C. ë‚˜íŠ¸ë¥¨ ì´ì˜¨ì˜ ìœ ì…\n",
            "\n",
            "D. ì—¼ì†Œ ì´ì˜¨ì˜ ìœ ì…\n",
            "\n",
            "ì •ë‹µ: C. ë‚˜íŠ¸ë¥¨ ì´ì˜¨ì˜ ìœ ì…\n",
            " í•´ì„¤: ë‚˜íŠ¸ë¥¨ ì´ì˜¨ì´ ì„¸í¬ ì•ˆìœ¼ë¡œ ë“¤ì–´ì˜¤ë©´ì„œ ë§‰ ì „ìœ„ê°€ ì–‘ì „í•˜ë¡œ ë³€í•˜ëŠ” ê²ƒì´ íƒˆë¶„ê·¹ì…ë‹ˆë‹¤.\n",
            "\n",
            "ë‚œì´ë„ ì¤‘ 10. ë‹¤ìŒ ì¤‘ ê°„ë‡Œ(diencephalon)ì— ì†í•˜ëŠ” êµ¬ì¡°ë¬¼ì´ ì•„ë‹Œ ê²ƒì€?\n",
            "\n",
            "A. ì‹œìƒ(thalamus)\n",
            "\n",
            "B. ì‹œìƒí•˜ë¶€(hypothalamus)\n",
            "\n",
            "C. ì†¡ê³¼ì„ (pineal gland)\n",
            "\n",
            "D. ì—°ìˆ˜(medulla oblongata)\n",
            "\n",
            "ì •ë‹µ: D. ì—°ìˆ˜(medulla oblongata)\n",
            " í•´ì„¤: ì—°ìˆ˜ëŠ” ë‡Œê°„ì— ì†í•˜ë©°, ê°„ë‡Œì—ëŠ” ì‹œìƒ, ì‹œìƒí•˜ë¶€, ì†¡ê³¼ì„ ì´ í¬í•¨ë©ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¶„í• **"
      ],
      "metadata": {
        "id": "8yUwnpBuQqRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from langchain_community.document_loaders import UnstructuredWordDocumentLoader\n",
        "\n",
        "# 2. ì²­í‚¹ì„ ìœ„í•œ ì •ê·œì‹ íŒ¨í„´ ì •ì˜\n",
        "pattern = r'(ë‚œì´ë„ í•˜ \\d+\\.|ë‚œì´ë„ ì¤‘ \\d+\\.|ë‚œì´ë„ ìƒ \\d+\\.)'\n",
        "\n",
        "# 3. ì»¤ìŠ¤í…€ ë¶„í•  í•¨ìˆ˜\n",
        "def question_splitter(text, pattern):\n",
        "    splits = re.split(pattern, text)\n",
        "    chunks = []\n",
        "    for i in range(1, len(splits), 2):\n",
        "        if i+1 < len(splits):\n",
        "            chunk = splits[i] + splits[i+1]\n",
        "            chunks.append(chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "# 4. ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ ë° ë¶„í• \n",
        "full_text = docs[0].page_content  # ë¡œë“œëœ ë¬¸ì„œì˜ ì „ì²´ í…ìŠ¤íŠ¸\n",
        "question_chunks = question_splitter(full_text, pattern)\n",
        "\n",
        "# 5. ê²°ê³¼ í™•ì¸\n",
        "for idx, chunk in enumerate(question_chunks[:3]):  # ìƒìœ„ 3ê°œ ìƒ˜í”Œ ì¶œë ¥\n",
        "    print(f\"=== ë¬¸ì œ {idx+1} ===\")\n",
        "    print(chunk)\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c05YqO-4SMB",
        "outputId": "34608a77-461f-4990-9e93-2f21d3a85be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ë¬¸ì œ 1 ===\n",
            "ë‚œì´ë„ í•˜ 1. ë‹¤ìŒ ì¤‘ ê°„(liver)ì—ì„œ ìˆ˜í–‰í•˜ì§€ ì•ŠëŠ” ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€?\n",
            "\n",
            "A. ì•Œë¶€ë¯¼(albumin) í•©ì„±\n",
            "\n",
            "B. ë‹´ì¦™(bile) ìƒì„±\n",
            "\n",
            "C. í˜ˆë‹¹ ì¡°ì ˆ(glucose regulation)\n",
            "\n",
            "D. ì¸ìŠë¦°(insulin) ë¶„ë¹„\n",
            "\n",
            "ì •ë‹µ: D. ì¸ìŠë¦°(insulin) ë¶„ë¹„\n",
            " í•´ì„¤: ì¸ìŠë¦°ì€ ì·Œì¥(ì´ì)ì—ì„œ ë¶„ë¹„ë˜ë©°, ê°„ì€ ì•Œë¶€ë¯¼ í•©ì„±, ë‹´ì¦™ ìƒì„±, í˜ˆë‹¹ ì¡°ì ˆì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.\n",
            "\n",
            "\n",
            "=== ë¬¸ì œ 2 ===\n",
            "ë‚œì´ë„ ì¤‘ 2. ê·¼ìˆ˜ì¶•(muscle contraction)ì— ì§ì ‘ì ìœ¼ë¡œ ê´€ì—¬í•˜ëŠ” ë‹¨ë°±ì§ˆ ë³µí•©ì²´ë¡œ ì˜³ì€ ê²ƒì€?\n",
            "\n",
            "A. ë¯¸ì˜¤ì‹ (myosin)ê³¼ íŠ¸ë¡œí¬ë‹Œ(troponin)\n",
            "\n",
            "B. íŠ¸ë¡œí¬ë‹Œ(troponin)ê³¼ íŠ¸ë¡œí¬ë§ˆì´ì˜¤ì‹ (tropomyosin)\n",
            "\n",
            "C. ì•¡í‹´(actin)ê³¼ ì½œë¼ê²(collagen)\n",
            "\n",
            "D. ì—˜ë¼ìŠ¤í‹´(elastin)ê³¼ ë¯¸ì˜¤ì‹ (myosin)\n",
            "\n",
            "ì •ë‹µ: B. íŠ¸ë¡œí¬ë‹Œ(troponin)ê³¼ íŠ¸ë¡œí¬ë§ˆì´ì˜¤ì‹ (tropomyosin)\n",
            " í•´ì„¤: íŠ¸ë¡œí¬ë‹Œê³¼ íŠ¸ë¡œí¬ë§ˆì´ì˜¤ì‹ ì€ ê·¼ìˆ˜ì¶• ì‹œ ì¹¼ìŠ˜ê³¼ ê²°í•©í•˜ì—¬ ì•¡í‹´-ë¯¸ì˜¤ì‹  ìƒí˜¸ì‘ìš©ì„ ì¡°ì ˆí•©ë‹ˆë‹¤.\n",
            "\n",
            "\n",
            "=== ë¬¸ì œ 3 ===\n",
            "ë‚œì´ë„ í•˜ 3. ë‹¤ìŒ ì¤‘ í˜ˆì•¡-ë‡Œ ì¥ë²½(blood-brain barrier)ì„ í†µê³¼í•˜ê¸° ê°€ì¥ ì‰¬ìš´ ë¬¼ì§ˆì€?\n",
            "\n",
            "A. í¬ë„ë‹¹(glucose)\n",
            "\n",
            "B. ì‚°ì†Œ(oxygen)\n",
            "\n",
            "C. ë‹¨ë°±ì§ˆ(protein)\n",
            "\n",
            "D. ë‚˜íŠ¸ë¥¨ ì´ì˜¨(sodium ion)\n",
            "\n",
            "ì •ë‹µ: B. ì‚°ì†Œ(oxygen)\n",
            " í•´ì„¤: ì‚°ì†ŒëŠ” ì§€ìš©ì„± ë¶„ìë¡œ, í˜ˆì•¡-ë‡Œ ì¥ë²½ì„ ê°€ì¥ ì‰½ê²Œ í†µê³¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3ë‹¨ê³„: ì„ë² ë”©**"
      ],
      "metadata": {
        "id": "jvkDZ65_7mm_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# 1. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
        "model_name = 'BM-K/KoSimCSE-roberta'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# 2. ì„ë² ë”© ì¶”ì¶œ í•¨ìˆ˜ ìˆ˜ì • (ë¬¸ì¥ ìˆ˜ì¤€ ì„ë² ë”©)\n",
        "def get_embeddings(sentences):\n",
        "    # ì…ë ¥: ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [\"ë¬¸ì¥1\", \"ë¬¸ì¥2\", ...])\n",
        "    inputs = tokenizer(\n",
        "        sentences,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512,  # ìµœëŒ€ ê¸¸ì´ ì œí•œ\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # [CLS] í† í° ì„ë² ë”© ì¶”ì¶œ (ì²« ë²ˆì§¸ í† í°)\n",
        "    # outputs.last_hidden_state.shape = (batch_size, seq_len, hidden_dim)\n",
        "    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "    # ì •ê·œí™” (ì„ íƒ ì‚¬í•­)\n",
        "    cls_embeddings = torch.nn.functional.normalize(cls_embeddings, p=2, dim=1)\n",
        "\n",
        "    return cls_embeddings\n",
        "\n",
        "# 3. ì˜ˆì‹œ: ì²­í‚¹ëœ ë¬¸ì œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©\n",
        "embeddings = get_embeddings(question_chunks)  # (num_chunks, 768) í˜•íƒœ í…ì„œ\n",
        "\n",
        "# 4. ì„ë² ë”© ê²°ê³¼ í™•ì¸\n",
        "print(embeddings.shape)  # â†’ torch.Size([ë¬¸í•­ê°œìˆ˜, 768])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTJWp-tl4SQw",
        "outputId": "cc8af081-f3fc-4ed4-d60e-f17c661c1242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4ë‹¨ê³„: FAISS ë²¡í„° ìŠ¤í† ì–´ ìƒì„±**"
      ],
      "metadata": {
        "id": "evf_f6Lh_HY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
        "save_dir = '/content/drive/MyDrive/tutor_store'\n",
        "\n",
        "# 1. ì„ë² ë”©ì„ NumPy ë°°ì—´ë¡œ ë³€í™˜ (KoSimCSE ì¶œë ¥ì´ PyTorch í…ì„œë¼ ê°€ì •)\n",
        "embeddings_np = embeddings.numpy().astype('float32')  # (num_chunks, 768)\n",
        "\n",
        "# 2. FAISS ì¸ë±ìŠ¤ ìƒì„± (L2 ê±°ë¦¬ ê¸°ì¤€)\n",
        "dimension = embeddings_np.shape[1]  # 768\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "# 3. ì„ë² ë”©ì„ ì¸ë±ìŠ¤ì— ì¶”ê°€\n",
        "faiss_index.add(embeddings_np)\n",
        "\n",
        "# 4. ë²¡í„°ìŠ¤í† ì–´ì™€ ì²­í¬ ë§¤í•‘ ì €ì¥\n",
        "faiss_path = os.path.join(save_dir, \"medical_qa_index.faiss\")\n",
        "chunk_path = os.path.join(save_dir, \"chunk_mapping.pkl\")\n",
        "\n",
        "# FAISS ì¸ë±ìŠ¤ ì €ì¥\n",
        "faiss.write_index(faiss_index, faiss_path)\n",
        "print(f\"FAISS ì¸ë±ìŠ¤ê°€ {faiss_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ì²­í¬ ë¦¬ìŠ¤íŠ¸ ì €ì¥ (ê²€ìƒ‰ ì‹œ í…ìŠ¤íŠ¸ ë³µì›ìš©)\n",
        "with open(chunk_path, 'wb') as f:\n",
        "    pickle.dump(question_chunks, f)\n",
        "print(f\"ì²­í¬ ë§¤í•‘ì´ {chunk_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOn1UZpw4SXX",
        "outputId": "888262c3-755d-4541-cbfe-90ddea502fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS ì¸ë±ìŠ¤ê°€ /content/drive/MyDrive/tutor_store/medical_qa_index.faissì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ì²­í¬ ë§¤í•‘ì´ /content/drive/MyDrive/tutor_store/chunk_mapping.pklì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5ë‹¨ê³„: tutor ì‹œìŠ¤í…œ êµ¬í˜„ (gemini-1.5-pro)"
      ],
      "metadata": {
        "id": "EAuwqYyvWbO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import gradio as gr\n",
        "from google.colab import drive, userdata\n",
        "from typing import List, Optional\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ ë° Gemini API í‚¤ ì„¤ì •\n",
        "drive.mount('/content/drive')\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('Gemini_API_KEY')\n",
        "\n",
        "# ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ ì„¤ì •\n",
        "store_dir = '/content/drive/MyDrive/tutor_store'\n",
        "faiss_path = os.path.join(store_dir, \"medical_qa_index.faiss\")\n",
        "chunk_path = os.path.join(store_dir, \"chunk_mapping.pkl\")\n",
        "\n",
        "# ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ\n",
        "faiss_index = faiss.read_index(faiss_path)\n",
        "with open(chunk_path, 'rb') as f:\n",
        "    question_chunks = pickle.load(f)\n",
        "\n",
        "# LLM ì´ˆê¸°í™”\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")\n",
        "\n",
        "# ì„¸ì…˜ ìƒíƒœ ì €ì¥ í´ë˜ìŠ¤\n",
        "class SessionState:\n",
        "    def __init__(self):\n",
        "        self.current_level = \"ë‚œì´ë„ í•˜\"\n",
        "        self.correct_count = 0\n",
        "        self.incorrect_count = 0\n",
        "        self.current_question = None\n",
        "        self.current_answer = None\n",
        "        self.question_ids = set()\n",
        "\n",
        "    @property\n",
        "    def total_attempts(self):\n",
        "        return self.correct_count + self.incorrect_count\n",
        "\n",
        "    @property\n",
        "    def success_rate(self):\n",
        "        return (self.correct_count / self.total_attempts) if self.total_attempts else 0\n",
        "\n",
        "    def update_stats(self, is_correct: bool):\n",
        "        if is_correct:\n",
        "            self.correct_count += 1\n",
        "            if self.current_level == \"ë‚œì´ë„ í•˜\" and self.success_rate >= 0.7 and self.total_attempts >= 3:\n",
        "                self.current_level = \"ë‚œì´ë„ ì¤‘\"\n",
        "            elif self.current_level == \"ë‚œì´ë„ ì¤‘\" and self.success_rate >= 0.7 and self.total_attempts >= 3:\n",
        "                self.current_level = \"ë‚œì´ë„ ìƒ\"\n",
        "        else:\n",
        "            self.incorrect_count += 1\n",
        "            if self.current_level == \"ë‚œì´ë„ ìƒ\" and self.success_rate < 0.5:\n",
        "                self.current_level = \"ë‚œì´ë„ ì¤‘\"\n",
        "            elif self.current_level == \"ë‚œì´ë„ ì¤‘\" and self.success_rate < 0.3:\n",
        "                self.current_level = \"ë‚œì´ë„ í•˜\"\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ í•¨ìˆ˜ë“¤\n",
        "def get_level_from_text(text: str) -> str:\n",
        "    if text.startswith(\"ë‚œì´ë„ í•˜\"): return \"ë‚œì´ë„ í•˜\"\n",
        "    if text.startswith(\"ë‚œì´ë„ ì¤‘\"): return \"ë‚œì´ë„ ì¤‘\"\n",
        "    if text.startswith(\"ë‚œì´ë„ ìƒ\"): return \"ë‚œì´ë„ ìƒ\"\n",
        "    match = re.match(r'(ë‚œì´ë„\\s*[í•˜ì¤‘ìƒ])', text)\n",
        "    return match.group(1) if match else \"ë‚œì´ë„ í•˜\"\n",
        "\n",
        "\n",
        "def process_question(text: str):\n",
        "    if \"ì •ë‹µ:\" not in text:\n",
        "        return text, \"\", \"\"\n",
        "    q_part = text.split(\"ì •ë‹µ:\")[0].strip()\n",
        "    a_full = text.split(\"ì •ë‹µ:\")[1].split(\"\\n\")[0].strip()\n",
        "    # ì •ë‹µì´ \"D. ì¸ìŠë¦°(insulin) ë¶„ë¹„\" í˜•íƒœì¼ ë•Œ ì²« ê¸€ìë§Œ ì¶”ì¶œ\n",
        "    a_part = a_full.split('.')[0].strip() if '.' in a_full else a_full\n",
        "    exp = text.split(\"í•´ì„¤:\")[1].strip() if \"í•´ì„¤:\" in text else \"\"\n",
        "    return q_part, a_part, exp\n",
        "\n",
        "\n",
        "def get_questions_by_level(level: str) -> List[str]:\n",
        "    return [q for q in question_chunks if get_level_from_text(q) == level]\n",
        "\n",
        "\n",
        "def select_next_question(session: SessionState) -> Optional[str]:\n",
        "    avail = get_questions_by_level(session.current_level)\n",
        "    unseen = [q for q in avail if hash(q) not in session.question_ids]\n",
        "    if unseen:\n",
        "        sel = np.random.choice(unseen)\n",
        "        session.question_ids.add(hash(sel))\n",
        "        return sel\n",
        "    for lvl in [\"ë‚œì´ë„ í•˜\", \"ë‚œì´ë„ ì¤‘\", \"ë‚œì´ë„ ìƒ\"]:\n",
        "        if lvl != session.current_level:\n",
        "            others = [q for q in get_questions_by_level(lvl) if hash(q) not in session.question_ids]\n",
        "            if others:\n",
        "                session.current_level = lvl\n",
        "                sel = np.random.choice(others)\n",
        "                session.question_ids.add(hash(sel))\n",
        "                return sel\n",
        "    session.question_ids.clear()\n",
        "    return np.random.choice(avail) if avail else None\n",
        "\n",
        "# LLM í”¼ë“œë°±ìš© í”„ë¡¬í”„íŠ¸\n",
        "feedback_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "ë‹¹ì‹ ì€ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ê³ ì‹œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì—ê²Œ ìœ ìµí•œ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”:\n",
        "\n",
        "ë¬¸ì œ: {question}\n",
        "í•™ìƒ ë‹µë³€: {user_answer}\n",
        "ì •ë‹µ: {correct_answer}\n",
        "\n",
        "{result_prefix}\n",
        "\n",
        "í”¼ë“œë°±ì„ ì œê³µí•  ë•Œ:\n",
        "1. í•™ìƒì˜ ì´í•´ë„ë¥¼ ê²©ë ¤í•˜ì„¸ìš”\n",
        "2. ì™œ í•´ë‹¹ ë‹µë³€ì´ ë§ê±°ë‚˜ í‹€ë ¸ëŠ”ì§€ ê°„ëµíˆ ì„¤ëª…í•˜ì„¸ìš”\n",
        "3. í•µì‹¬ ê°œë…ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”\n",
        "\"\"\")\n",
        "\n",
        "def hide_answer_from_question(text: str) -> str:\n",
        "    return text.split(\"ì •ë‹µ:\")[0].strip() if \"ì •ë‹µ:\" in text else text\n",
        "\n",
        "# í”¼ë“œë°± ìƒì„± í•¨ìˆ˜\n",
        "def generate_feedback(session: SessionState, user_answer: str, is_correct: bool) -> str:\n",
        "    try:\n",
        "        question, _, _ = process_question(session.current_question)\n",
        "        prompt = feedback_prompt.format(\n",
        "            question=question,\n",
        "            user_answer=user_answer,\n",
        "            correct_answer=session.current_answer,\n",
        "            result_prefix=\"ì •ë‹µì…ë‹ˆë‹¤!\" if is_correct else \"ì•„ì‰½ê²Œë„ ì˜¤ë‹µì…ë‹ˆë‹¤.\"\n",
        "        )\n",
        "        resp = llm.invoke(prompt)\n",
        "        fb = resp.content\n",
        "    except Exception:\n",
        "        fb = (\"ì •ë‹µì…ë‹ˆë‹¤!\" if is_correct else \"ì˜¤ë‹µì…ë‹ˆë‹¤.\") + f\" ì •ë‹µì€ {session.current_answer}ì…ë‹ˆë‹¤.\"\n",
        "    if not is_correct:\n",
        "        fb += f\"\\n\\n**ì •ë‹µ**: {session.current_answer}\"\n",
        "    _, _, exp = process_question(session.current_question)\n",
        "    if exp:\n",
        "        fb += f\"\\n\\n**í•´ì„¤**: {exp}\"\n",
        "    return fb\n",
        "\n",
        "# ë‹¤ìŒ ë¬¸ì œ ì¤€ë¹„ í•¨ìˆ˜\n",
        "def prepare_next_question(session: SessionState) -> str:\n",
        "    nxt = select_next_question(session)\n",
        "    if not nxt:\n",
        "        return \"**ëª¨ë“  ë¬¸ì œë¥¼ í’€ì—ˆìŠµë‹ˆë‹¤! ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.**\"\n",
        "    q, a, _ = process_question(nxt)\n",
        "    session.current_question = nxt\n",
        "    session.current_answer = a\n",
        "    q_only = hide_answer_from_question(q)\n",
        "    info = (f\"**í•™ìŠµ ì§„í–‰ ìƒí™©**\\n\"\n",
        "            f\"- í˜„ì¬ ë‚œì´ë„: {session.current_level}\\n\"\n",
        "            f\"- í‘¼ ë¬¸ì œ: {session.total_attempts}ë¬¸ì œ\\n\"\n",
        "            f\"- ë§ì¶˜ ë¬¸ì œ: {session.correct_count}ë¬¸ì œ\\n\"\n",
        "            f\"- í‹€ë¦° ë¬¸ì œ: {session.incorrect_count}ë¬¸ì œ\\n\\n\")\n",
        "    return info + f\"**ë‹¤ìŒ ë¬¸ì œ**\\n{q_only}\"\n",
        "\n",
        "# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜\n",
        "def chat_interface(message, history, session_state):\n",
        "    if not message or not message.strip():\n",
        "        return history, \"\"\n",
        "    # ì²« ì§ˆë¬¸\n",
        "    if not history:\n",
        "        q_full = select_next_question(session_state)\n",
        "        if not q_full:\n",
        "            return [{\"role\": \"assistant\", \"content\": \"ë¬¸ì œë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"}], \"\"\n",
        "        q, a, _ = process_question(q_full)\n",
        "        session_state.current_question = q_full\n",
        "        session_state.current_answer = a\n",
        "        return [\n",
        "            {\"role\": \"assistant\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ê³ ì‹œ ë¬¸ì œ í’€ì´ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\"},\n",
        "            {\"role\": \"assistant\", \"content\": hide_answer_from_question(q)}\n",
        "        ], \"\"\n",
        "    # ë‹µì•ˆ ì²˜ë¦¬\n",
        "    new_hist = history.copy()\n",
        "    user_ans = message.strip().upper()\n",
        "    new_hist.append({\"role\": \"user\", \"content\": user_ans})\n",
        "    correct = (user_ans == session_state.current_answer.upper())\n",
        "    session_state.update_stats(correct)\n",
        "    fb = generate_feedback(session_state, user_ans, correct)\n",
        "    nxt_q = prepare_next_question(session_state)\n",
        "    new_hist.append({\"role\": \"assistant\", \"content\": fb + \"\\n\\n\" + nxt_q})\n",
        "    return new_hist, \"\"\n",
        "\n",
        "# ë²„íŠ¼ í´ë¦­ ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def answer_click(answer, history, session_state):\n",
        "    new_history, _ = chat_interface(answer, history, session_state)\n",
        "    return new_history\n",
        "\n",
        "# ì„¸ì…˜ ì´ˆê¸°í™” í•¨ìˆ˜\n",
        "def clear_chat():\n",
        "    new_sess = SessionState()\n",
        "    first = select_next_question(new_sess)\n",
        "    q, a, _ = process_question(first)\n",
        "    new_sess.current_question = first\n",
        "    new_sess.current_answer = a\n",
        "    return new_sess, [\n",
        "        {\"role\": \"assistant\", \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ê³ ì‹œ ë¬¸ì œ í’€ì´ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\"},\n",
        "        {\"role\": \"assistant\", \"content\": hide_answer_from_question(q)}\n",
        "    ]\n",
        "\n",
        "# Gradio UI êµ¬ì„±\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    .gradio-container {max-width: 900px; margin: auto;}\n",
        "    .chat-history {height: 600px !important;}\n",
        "    footer {display: none !important;}\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"# ğŸ“ ì‘ì—…ì¹˜ë£Œì‚¬ êµ­ê°€ê³ ì‹œ ë¬¸ì œ í•™ìŠµ ì±—ë´‡\")\n",
        "    gr.Markdown(\"ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹µì•ˆì„ ì„ íƒí•˜ì„¸ìš”.\")\n",
        "\n",
        "    session_state = gr.State(SessionState())\n",
        "    chatbot = gr.Chatbot(label=\"í•™ìŠµ ëŒ€í™”\", height=500, type=\"messages\", render_markdown=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        btn_A = gr.Button(\"A\")\n",
        "        btn_B = gr.Button(\"B\")\n",
        "        btn_C = gr.Button(\"C\")\n",
        "        btn_D = gr.Button(\"D\")\n",
        "        clear_btn = gr.Button(\"ì´ˆê¸°í™”\")\n",
        "\n",
        "    btn_A.click(lambda history, ss: answer_click(\"A\", history, ss), inputs=[chatbot, session_state], outputs=[chatbot])\n",
        "    btn_B.click(lambda history, ss: answer_click(\"B\", history, ss), inputs=[chatbot, session_state], outputs=[chatbot])\n",
        "    btn_C.click(lambda history, ss: answer_click(\"C\", history, ss), inputs=[chatbot, session_state], outputs=[chatbot])\n",
        "    btn_D.click(lambda history, ss: answer_click(\"D\", history, ss), inputs=[chatbot, session_state], outputs=[chatbot])\n",
        "\n",
        "    clear_btn.click(clear_chat, outputs=[session_state, chatbot])\n",
        "    demo.load(clear_chat, outputs=[session_state, chatbot])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "_BUAU9gZvMa7",
        "outputId": "c0413a79-99e1-4719-f53f-599cdcdc217a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://59745050e818cf11fa.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://59745050e818cf11fa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-V0njr8zCjG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}